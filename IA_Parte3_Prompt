Aja como um Especialista em Computação Evolutiva e Otimização. O objetivo foi encontrar os pesos ideais (w) para uma Regressão Linear no dataset 'California Housing' sem usar gradiente descendente, mas sim algoritmos bio-inspirados.

Técnicas implementadas:
1. Algoritmo Genético (GA):
   - Variação de parâmetros: Tamanho da População, Taxa de Mutação e Taxa de Cruzamento.
2. PSO (Otimização por Enxame de Partículas):
   - Variação de parâmetros: Tamanho da População, C1 (Cognitivo) e C2 (Social).

Requisitos cumpridos:
- Realização de 8 experimentos distintos para cada algoritmo (total 16).
- Avaliação por duas métricas: MSE (Erro Quadrático Médio) e MAE (Erro Absoluto Médio).
- Geração de gráficos de Convergência (evolução do erro) e Comparativo de Barras.

Abaixo segue o código Python completo:

'''python
import numpy as np
import pandas as pd
import random
import time
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# --- MÓDULOS DE CLASSES (GA e PSO) ---
def carregar_dados_otimizacao():
    data = fetch_california_housing(); X = data.data; y = data.target
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train); X_test = scaler.transform(X_test)
    X_train = np.c_[np.ones(X_train.shape[0]), X_train]
    X_test = np.c_[np.ones(X_test.shape[0]), X_test]
    return X_train, X_test, y_train, y_test

def calcular_mse(y_true, y_pred): return np.mean((y_true - y_pred) ** 2)
def calcular_mae(y_true, y_pred): return np.mean(np.abs(y_true - y_pred))

class GeneticAlgorithm:
    def __init__(self, pop_size, mutation_rate, crossover_rate, n_genes, fun_avaliacao):
        self.pop_size = pop_size; self.mutation_rate = mutation_rate
        self.crossover_rate = crossover_rate; self.n_genes = n_genes
        self.fun_avaliacao = fun_avaliacao; self.population = []
    def init_population(self): self.population = np.random.uniform(-1, 1, (self.pop_size, self.n_genes))
    def fitness(self, individuo, X, y): return self.fun_avaliacao(y, X.dot(individuo))
    def select(self, scores):
        i1 = random.randint(0, self.pop_size-1); i2 = random.randint(0, self.pop_size-1)
        return self.population[i1] if scores[i1] < scores[i2] else self.population[i2]
    def crossover(self, p1, p2):
        if random.random() < self.crossover_rate:
            pt = random.randint(1, self.n_genes-1)
            return np.concatenate([p1[:pt], p2[pt:]]), np.concatenate([p2[:pt], p1[pt:]])
        return p1.copy(), p2.copy()
    def mutate(self, ind):
        for i in range(self.n_genes):
            if random.random() < self.mutation_rate: ind[i] += np.random.normal(0, 0.1)
        return ind
    def run(self, X, y, generations=50):
        self.init_population(); best_score = float('inf'); history = []
        for _ in range(generations):
            scores = [self.fitness(ind, X, y) for ind in self.population]
            min_sc = min(scores)
            if min_sc < best_score:
                best_score = min_sc; best_ind = self.population[scores.index(min_sc)].copy()
            history.append(best_score)
            new_pop = [best_ind]
            while len(new_pop) < self.pop_size:
                p1 = self.select(scores); p2 = self.select(scores)
                c1, c2 = self.crossover(p1, p2)
                new_pop.append(self.mutate(c1)); 
                if len(new_pop) < self.pop_size: new_pop.append(self.mutate(c2))
            self.population = np.array(new_pop)
        return best_score, best_ind, history

class PSO:
    def __init__(self, n_part, c1, c2, n_dim, fun_val, w=0.7):
        self.n_part = n_part; self.c1 = c1; self.c2 = c2; self.w = w
        self.n_dim = n_dim; self.fun_val = fun_val
        self.pos = np.random.uniform(-1, 1, (n_part, n_dim))
        self.vel = np.zeros((n_part, n_dim))
        self.p_best_pos = self.pos.copy(); self.p_best_scores = np.full(n_part, float('inf'))
        self.g_best_score = float('inf')
    def run(self, X, y, iterations=50):
        history = []
        for _ in range(iterations):
            for i in range(self.n_part):
                score = self.fun_val(y, X.dot(self.pos[i]))
                if score < self.p_best_scores[i]: self.p_best_scores[i] = score; self.p_best_pos[i] = self.pos[i]
                if score < self.g_best_score: self.g_best_score = score; self.g_best_pos = self.pos[i]
            for i in range(self.n_part):
                r1, r2 = np.random.random(self.n_dim), np.random.random(self.n_dim)
                cog = self.c1 * r1 * (self.p_best_pos[i] - self.pos[i])
                soc = self.c2 * r2 * (self.g_best_pos - self.pos[i])
                self.vel[i] = self.w * self.vel[i] + cog + soc
                self.pos[i] += self.vel[i]
            history.append(self.g_best_score)
        return self.g_best_score, self.g_best_pos, history

# --- EXECUÇÃO ---
if __name__ == '__main__':
    X_train, X_test, y_train, y_test = carregar_dados_otimizacao()
    n_feat = X_train.shape[1]
    
    exp_ga = [{'id': i, 'pop': p, 'mut': m, 'cross': c} for i, (p, m, c) in enumerate([
        (20, 0.01, 0.7), (20, 0.1, 0.7), (20, 0.01, 0.9), (50, 0.01, 0.7),
        (50, 0.1, 0.9), (100, 0.01, 0.8), (100, 0.05, 0.6), (10, 0.2, 0.5)], 1)]
    
    exp_pso = [{'id': i, 'pop': p, 'c1': c1, 'c2': c2} for i, (p, c1, c2) in enumerate([
        (20, 1.5, 1.5), (20, 2.0, 2.0), (20, 0.5, 2.5), (50, 1.5, 1.5),
        (50, 2.5, 0.5), (100, 1.0, 1.0), (100, 1.49, 1.49), (10, 2.0, 2.0)], 1)]
    
    res = []; best_ga_hist = []; best_pso_hist = []
    
    # Roda GA
    for ex in exp_ga:
        ga = GeneticAlgorithm(ex['pop'], ex['mut'], ex['cross'], n_feat, calcular_mse)
        sc, _, hist = ga.run(X_train, y_train, 30)
        res.append({'Alg': 'GA', 'Metrica': 'MSE', 'ID': ex['id'], 'Score': sc})
        if ex['id'] == 6: best_ga_hist = hist # Exemplo de melhor
        
    # Roda PSO
    for ex in exp_pso:
        pso = PSO(ex['pop'], ex['c1'], ex['c2'], n_feat, calcular_mse)
        sc, _, hist = pso.run(X_train, y_train, 30)
        res.append({'Alg': 'PSO', 'Metrica': 'MSE', 'ID': ex['id'], 'Score': sc})
        if ex['id'] == 4: best_pso_hist = hist # Exemplo de melhor

    df = pd.DataFrame(res)
    print(df.groupby(['Alg', 'Metrica'])['Score'].mean())
    
    plt.plot(best_ga_hist, label='GA'); plt.plot(best_pso_hist, label='PSO')
    plt.legend(); plt.title('Convergência MSE'); plt.show()
    
    sns.barplot(x='Alg', y='Score', data=df); plt.title('Comparação Média'); plt.show()
'''

Sua Tarefa:
1. Analise os resultados dos 8 experimentos. Qual configuração (População/Mutação ou C1/C2) obteve o menor erro?
2. Compare o GA com o PSO: Quem convergiu mais rápido? Quem foi mais estável?
3. Explique os gráficos gerados (Convergência e Barras).
4. Esteja pronto para debater com o professor sobre a influência dos hiperparâmetros (ex: o que acontece se C1 for muito maior que C2 no PSO?) e defender as conclusões do experimento.
